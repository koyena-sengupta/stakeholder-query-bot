ğŸ“Š Stakeholder Query Bot (RAG-Based)

A Retrieval-Augmented Generation (RAG) powered chatbot that answers stakeholder queries using internal project documents.

Built as a Proof of Concept (POC) using:

Streamlit (UI)

OpenAI LLM

ChromaDB (Vector Store)

LangChain (RAG orchestration)

ğŸš€ Problem Statement

Stakeholders often ask repetitive questions about:

SLAs

Escalation matrix

Security policies

Project timelines

Technical architecture

Manually responding to these queries leads to:

Delays

Context switching

Inconsistent responses

This solution enables:

Instant document-grounded answers

Reduced manual effort

Controlled hallucination via RAG

ğŸ§  Architecture Overview

User Question
â†“
Query Embedding
â†“
Vector Search (ChromaDB)
â†“
Top-K Relevant Chunks Retrieved
â†“
Context Injected into LLM
â†“
Grounded Answer Returned

ğŸ“‚ Project Structure
stakeholder-query-bot/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Streamlit UI
â”‚   â”œâ”€â”€ ingest.py            # Document ingestion pipeline
â”‚   â”œâ”€â”€ rag_pipeline.py      # Retrieval + LLM logic
â”‚   â””â”€â”€ config.py            # Central configuration
â”‚
â”œâ”€â”€ data/raw/                # Dummy internal documents
â”œâ”€â”€ vectorstore/             # Auto-generated embeddings (gitignored)
â”‚
â”œâ”€â”€ .env                     # API keys (not committed)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone Repository
git clone <your-repo-url>
cd stakeholder-query-bot

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Add OpenAI API Key

Create a .env file:

OPENAI_API_KEY=your_api_key_here

5ï¸âƒ£ Add Documents

Place internal documents inside:

data/raw/


Supported formats:

PDF

DOCX

TXT

6ï¸âƒ£ Run Ingestion
python app/ingest.py


This creates the vector database.

7ï¸âƒ£ Start the Application
streamlit run app/main.py

ğŸ’¬ Example Questions

What is the SLA for high priority issues?

When is InsightX going live?

What is the password policy?

What database is used in the system?

Who approves budget changes?

Out-of-scope test:

What is the companyâ€™s annual revenue?

ğŸ” Guardrails

Answers strictly based on embedded documents

No hallucinated responses

Out-of-context questions return a fallback response

ğŸ›  Tech Stack

Python

Streamlit

OpenAI (LLM + Embeddings)

ChromaDB

LangChain

ğŸ“Œ Key Features

âœ” Document-grounded responses
âœ” Modular RAG pipeline
âœ” Persistent vector storage
âœ” Clean UI for demo
âœ” Easy to extend

ğŸ”® Future Improvements

Add document upload via UI

Add source citation highlighting

Add answer confidence score

Deploy to Azure / Streamlit Cloud

Add authentication