# ğŸ“Š Stakeholder Query Bot (RAG-Based)

A **Retrieval-Augmented Generation (RAG)** powered chatbot that answers stakeholder queries using internal project documents.

Built as a **Proof of Concept (POC)** using:

* **Streamlit** â€“ for the UI
* **OpenAI LLM** â€“ for natural language responses
* **ChromaDB** â€“ vector database for document embeddings
* **LangChain** â€“ for orchestrating the RAG pipeline

---

## ğŸš€ Problem Statement

Stakeholders often ask repetitive questions about:

* SLAs and escalation matrix
* Security policies
* Project timelines
* Technical architecture

Manually responding leads to:

* Delays
* Context switching
* Inconsistent answers

**Solution:** a chatbot that provides **document-grounded, instant, accurate answers**.

---

## ğŸ§  Architecture Overview

```
User Question
      â†“
Query Embedding
      â†“
Vector Search (ChromaDB)
      â†“
Top-K Relevant Document Chunks
      â†“
Context + LLM â†’ Grounded Answer
      â†“
Answer Displayed in Streamlit
```

---

## ğŸ“‚ Project Structure

```
stakeholder-query-bot/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py         # Streamlit UI
â”‚   â”œâ”€â”€ ingest.py       # Document ingestion pipeline
â”‚   â”œâ”€â”€ rag_pipeline.py # Retrieval + LLM logic
â”‚   â””â”€â”€ config.py       # Central configuration
â”‚
â”œâ”€â”€ data/raw/           # Dummy project documents
â”œâ”€â”€ vectorstore/        # Auto-generated vector DB (gitignored)
â”‚
â”œâ”€â”€ .env                # API keys
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/YOUR_USERNAME/stakeholder-query-bot.git
cd stakeholder-query-bot
```

---

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
# Mac/Linux
source venv/bin/activate
# Windows
venv\Scripts\activate
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Add OpenAI API Key

Create a `.env` file:

```text
OPENAI_API_KEY=your_api_key_here
```

---

### 5ï¸âƒ£ Add Documents

Place project documents inside:

```
data/raw/
```

Supported formats: `.pdf`, `.docx`, `.txt`

---

### 6ï¸âƒ£ Run Ingestion

```bash
python app/ingest.py
```

This will create the **vector database**.

---

### 7ï¸âƒ£ Start the Application

```bash
streamlit run app/main.py
```

---

## ğŸ’¬ Example Questions

* What is the SLA for high priority issues?
* When is InsightX going live?
* What is the password policy?
* What database is used in the system?
* Who approves budget changes?

**Out-of-scope test:**

* What is the companyâ€™s annual revenue? â†’ Should return:

> "I could not find this information in the knowledge base."

---

## ğŸ” Guardrails

* Answers **strictly based on embedded documents**
* Out-of-context questions return a fallback response
* No hallucinations

---

## ğŸ›  Tech Stack

* Python
* Streamlit
* OpenAI (LLM + Embeddings)
* ChromaDB
* LangChain

---

## ğŸ”® Future Improvements

* Document upload via UI
* Highlighting source citations in answers
* Answer confidence scoring
* Deploy to Streamlit Cloud / Azure
* Add authentication
